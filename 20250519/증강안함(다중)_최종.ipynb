{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om4ittXxN-O3",
        "outputId": "6050bcf6-86d2-4052-de26-2fdcd2226bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dfW7fkstmalu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.metrics import specificity_score # specificity_score 임포트\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Conv1D, Flatten\n",
        "import seaborn as sns\n",
        "from scipy.spatial.distance import euclidean\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PBqLiRHQmfcM"
      },
      "outputs": [],
      "source": [
        "df_X_train = pd.read_csv('/content/drive/My Drive/PhalangesOutlinesCorrect/X_train_Worms.csv')\n",
        "df_y_train = pd.read_csv('/content/drive/My Drive/PhalangesOutlinesCorrect/y_train_Worms.csv')\n",
        "df_X_test = pd.read_csv('/content/drive/MyDrive/PhalangesOutlinesCorrect/X_test_Worms.csv')\n",
        "df_y_test = pd.read_csv('/content/drive/MyDrive/PhalangesOutlinesCorrect/y_test_Worms.csv')\n",
        "X_train = df_X_train.values\n",
        "y_train = df_y_train.values.reshape(-1)  # 1차원 배열(벡터)로 변환\n",
        "X_test = df_X_test.values\n",
        "y_test = df_y_test.values.reshape(-1)  # 1차원 배열(벡터)로 변환\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Label 인코딩\n",
        "le = LabelEncoder()\n",
        "y_synthetic_encoded = le.fit_transform(y_train)\n",
        "y_test_encoded = le.transform(y_test)\n",
        "num_classes = len(np.unique(y_synthetic_encoded))\n",
        "\n",
        "# One-hot encoding\n",
        "y_synthetic_cat = to_categorical(y_synthetic_encoded, num_classes=num_classes)\n",
        "y_test_cat = to_categorical(y_test_encoded, num_classes=num_classes)\n"
      ],
      "metadata": {
        "id": "K4l0fEk0MywF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_logistic_regression(X_train, y_train, X_test):\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    return model.predict(X_test)\n",
        "\n",
        "def predict_with_cart(X_train, y_train, X_test):\n",
        "    model = DecisionTreeClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "    return model.predict(X_test)\n",
        "\n",
        "def predict_with_knn(X_train, y_train, X_test, k=3):\n",
        "    model = KNeighborsClassifier(n_neighbors=k)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model.predict(X_test)\n",
        "\n",
        "def predict_with_xgboost(X_train, y_train, X_test, label_encoder=None):\n",
        "    from xgboost import XGBClassifier\n",
        "\n",
        "    model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "    model.fit(X_train, y_train)\n",
        "    pred_y = model.predict(X_test)\n",
        "\n",
        "    if label_encoder is not None:\n",
        "        pred_y = label_encoder.inverse_transform(pred_y)\n",
        "\n",
        "    return pred_y\n",
        "\n",
        "def predict_with_lstm(X_train, y_train, X_test, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "    model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "    pred_prob = model.predict(X_test_reshaped)\n",
        "    return np.argmax(pred_prob, axis=1)\n",
        "\n",
        "\n",
        "def predict_with_cnn(X_train, y_train, X_test, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "    model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "    pred_prob = model.predict(X_test_reshaped)\n",
        "    return np.argmax(pred_prob, axis=1)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VW13kwNJ-e7L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = {\n",
        "    \"Logistic Regression\": predict_with_logistic_regression(X_train, y_synthetic_encoded, X_test),\n",
        "    \"CART\": predict_with_cart(X_train, y_synthetic_encoded, X_test),\n",
        "    \"KNN\": predict_with_knn(X_train, y_synthetic_encoded, X_test),\n",
        "    \"XGBoost\": predict_with_xgboost(X_train, y_synthetic_encoded, X_test),\n",
        "    \"LSTM\": predict_with_lstm(X_train, y_synthetic_cat, X_test, num_classes),\n",
        "    \"CNN\": predict_with_cnn(X_train, y_synthetic_cat, X_test, num_classes)\n",
        "}\n",
        "\n",
        "\n",
        "# 성능 지표 저장을 위한 리스트\n",
        "results = []\n",
        "for model_name, pred_y in predictions.items():\n",
        "    accuracy = accuracy_score(y_test_encoded, pred_y)\n",
        "    recall = recall_score(y_test_encoded, pred_y, average='macro')\n",
        "    f1 = f1_score(y_test_encoded, pred_y, average='macro')\n",
        "    specificity = specificity_score(y_test_encoded, pred_y, average='macro')\n",
        "    conf_matrix = confusion_matrix(y_test_encoded, pred_y)\n",
        "    results.append([accuracy, f1, recall, specificity, conf_matrix])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7qd9sB6_vFk",
        "outputId": "50789878-11b8-4348-ac84-ec28772c70d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:22:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 215ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능 지표를 DataFrame으로 변환\n",
        "results_df = pd.DataFrame(results, columns=[\"Accuracy\", \"F1\", \"Recall\", \"Specificity\", \"Confusion Matrix\"], index=predictions.keys())\n",
        "model_results = results_df.T\n",
        "# 결과를 출력\n",
        "print(\"\\n모델 성능 비교 결과:\")\n",
        "print(model_results)\n",
        "\n",
        "# 결과를 CSV 파일로 저장\n",
        "model_results.to_csv(\"/content/drive/My Drive/PhalangesOutlinesCorrect/results/(다중)증강안함.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua7CnK0VBYzk",
        "outputId": "5a72945d-3113-4b90-d0a8-1ee6840e3318"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "모델 성능 비교 결과:\n",
            "                                                Logistic Regression  \\\n",
            "Accuracy                                                   0.350649   \n",
            "F1                                                         0.305043   \n",
            "Recall                                                     0.356387   \n",
            "Specificity                                                 0.82784   \n",
            "Confusion Matrix  [[14, 1, 4, 8, 6], [3, 1, 3, 4, 2], [4, 1, 3, ...   \n",
            "\n",
            "                                                               CART  \\\n",
            "Accuracy                                                   0.467532   \n",
            "F1                                                         0.427157   \n",
            "Recall                                                     0.438228   \n",
            "Specificity                                                0.853046   \n",
            "Confusion Matrix  [[19, 2, 4, 3, 5], [5, 3, 2, 2, 1], [3, 2, 5, ...   \n",
            "\n",
            "                                                                KNN  \\\n",
            "Accuracy                                                   0.363636   \n",
            "F1                                                         0.271208   \n",
            "Recall                                                      0.28669   \n",
            "Specificity                                                0.817737   \n",
            "Confusion Matrix  [[19, 1, 3, 9, 1], [6, 0, 2, 2, 3], [5, 1, 3, ...   \n",
            "\n",
            "                                                            XGBoost  \\\n",
            "Accuracy                                                   0.506494   \n",
            "F1                                                         0.443414   \n",
            "Recall                                                     0.433147   \n",
            "Specificity                                                0.851412   \n",
            "Confusion Matrix  [[24, 1, 2, 4, 2], [10, 2, 0, 0, 1], [2, 1, 4,...   \n",
            "\n",
            "                                                               LSTM  \\\n",
            "Accuracy                                                   0.428571   \n",
            "F1                                                             0.12   \n",
            "Recall                                                          0.2   \n",
            "Specificity                                                     0.8   \n",
            "Confusion Matrix  [[33, 0, 0, 0, 0], [13, 0, 0, 0, 0], [10, 0, 0...   \n",
            "\n",
            "                                                                CNN  \n",
            "Accuracy                                                   0.363636  \n",
            "F1                                                         0.334719  \n",
            "Recall                                                     0.343217  \n",
            "Specificity                                                0.826399  \n",
            "Confusion Matrix  [[15, 0, 4, 11, 3], [7, 2, 3, 0, 1], [3, 3, 3,...  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}